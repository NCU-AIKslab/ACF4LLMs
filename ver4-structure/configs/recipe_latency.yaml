# Latency/VRAM-balanced recipe: Optimize for speed and memory efficiency
name: "latency_optimized"
description: "Balance accuracy with latency and VRAM constraints using aggressive optimizations"
version: "1.0"

# Base model configuration
base_model: "Qwen/Qwen2.5-Math-7B"
tokenizer_model: "Qwen/Qwen2.5-Math-7B"

# Multi-objective targets (weights for optimization)
targets:
  objective_weights:
    accuracy: 0.6      # Still important but not primary
    latency: 1.0       # Primary objective
    vram: 1.0          # Primary objective
    co2: 0.2           # Secondary consideration

# Optimization pipeline stages
pipeline:
  - stage: quantize_bnb
    enabled: true
    args:
      quant_type: "nf4"
      compute_dtype: "bfloat16"
      bnb_4bit_use_double_quant: false  # Faster but less accurate
      bnb_4bit_quant_type: "nf4"

  - stage: prune_sparsity
    enabled: true
    args:
      sparsity_ratio: 0.5
      structured_sparsity: "2:4"
      layers_to_prune: ["attention.ffn", "attention.proj"]
      recovery_finetune: true
      recovery_epochs: 1

  - stage: distill_lora
    enabled: true
    args:
      lora_r: 16        # Smaller rank for speed
      lora_alpha: 32
      lora_dropout: 0.1
      target_modules: ["q_proj", "v_proj", "gate_proj", "up_proj"]  # Fewer modules
      learning_rate: 5e-4
      num_epochs: 1     # Single epoch for speed
      warmup_ratio: 0.05
      weight_decay: 0.0
      gradient_accumulation_steps: 2
      per_device_train_batch_size: 4  # Larger batches
      dataloader_num_workers: 8
      save_strategy: "no"
      evaluation_strategy: "no"  # Skip intermediate evaluations
      logging_steps: 50

  - stage: kv_runtime
    enabled: true
    args:
      flash_attn: true
      vllm: false
      max_sequence_length: 1024  # Shorter sequences

  - stage: rag
    enabled: false  # Disable RAG for speed

# Generation/decoding parameters (optimized for speed)
decode:
  temperature: 0.0    # Greedy decoding for speed
  top_p: 1.0
  top_k: 1
  max_new_tokens: 192  # Shorter responses
  do_sample: false
  num_beams: 1
  repetition_penalty: 1.0
  length_penalty: 0.9  # Encourage shorter responses

# Dataset configuration
dataset:
  name: "openai/gsm8k"
  val_split_size: 500   # Smaller validation set
  augmentation_recipes: []  # No augmentation for speed
  max_samples_train: 5000   # Limited training data
  max_samples_eval: null
  random_seed: 42

# Evaluation configuration
evaluation:
  batch_size: 16      # Larger batches for throughput
  num_warmup_batches: 1
  save_predictions: false
  error_analysis: false
  carbon_tracking: true

# Resource limits
resource_limits:
  max_vram_gb: 16     # Tighter VRAM constraint
  max_training_hours: 2
  max_eval_time_minutes: 15
  early_stopping_patience: 3

# Logging and tracking
tracking:
  mlflow_experiment: "gsm8k_latency_optimization"
  mlflow_tracking_uri: "file:./mlruns"
  log_level: "WARNING"  # Less logging
  save_checkpoints: false
  checkpoint_dir: "./checkpoints/latency_optimized"

# Hardware optimizations
hardware:
  use_mixed_precision: true
  dataloader_pin_memory: true
  torch_compile: true   # Enable compilation optimizations
  gradient_checkpointing: false  # Trade memory for speed