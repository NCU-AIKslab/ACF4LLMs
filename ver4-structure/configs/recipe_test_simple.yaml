# Simple test recipe: Only BnB quantization for testing
name: "test_simple"
description: "Simple test recipe with only BnB quantization for system validation"
version: "1.0"

# Base model configuration
base_model: "Qwen/Qwen2.5-Math-1.5B"
tokenizer_model: "Qwen/Qwen2.5-Math-1.5B"

# Multi-objective targets
targets:
  objective_weights:
    accuracy: 1.0
    latency: 0.2
    vram: 0.5
    co2: 0.1

# Simple optimization pipeline - only quantization
pipeline:
  - stage: quantize_bnb
    enabled: true
    args:
      quant_type: "nf4"
      compute_dtype: "float16"
      bnb_4bit_use_double_quant: true

# Generation parameters
decode:
  temperature: 0.1
  top_p: 0.9
  max_new_tokens: 150
  do_sample: false

# Dataset configuration
dataset:
  name: "openai/gsm8k"
  val_split_size: 200
  augmentation_recipes: []
  random_seed: 42

# Evaluation configuration
evaluation:
  batch_size: 1
  num_warmup_batches: 0
  save_predictions: false
  error_analysis: false
  carbon_tracking: true

# Resource limits
resource_limits:
  max_vram_gb: 8
  max_training_hours: 1
  max_eval_time_minutes: 30
  early_stopping_patience: 3
  fail_on_stage_error: true

# Logging
tracking:
  mlflow_experiment: "gsm8k_test_simple"
  mlflow_tracking_uri: "file:./mlruns"
  log_level: "INFO"
  save_checkpoints: false

# Hardware settings
hardware:
  use_mixed_precision: true