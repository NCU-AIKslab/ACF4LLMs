# Hyperparameter optimization search spaces for GSM8K optimization
# Defines the parameter ranges for multi-objective optimization

# Decoding/Generation parameters
decode:
  temperature:
    type: "float"
    low: 0.1
    high: 0.9
    distribution: "uniform"

  top_p:
    type: "float"
    low: 0.7
    high: 1.0
    distribution: "uniform"

  max_new_tokens:
    type: "int"
    low: 128
    high: 384
    step: 32

  num_beams:
    type: "categorical"
    choices: [1, 2, 4]

  repetition_penalty:
    type: "float"
    low: 1.0
    high: 1.2
    distribution: "uniform"

# LoRA/QLoRA parameters
lora:
  lora_r:
    type: "categorical"
    choices: [8, 16, 32, 64]

  lora_alpha:
    type: "categorical"
    choices: [16, 32, 64, 128]

  lora_dropout:
    type: "float"
    low: 0.0
    high: 0.2
    distribution: "uniform"

  learning_rate:
    type: "float"
    low: 5.0e-5
    high: 5.0e-4
    distribution: "log"

  num_epochs:
    type: "int"
    low: 1
    high: 3

  warmup_ratio:
    type: "float"
    low: 0.03
    high: 0.15
    distribution: "uniform"

  weight_decay:
    type: "float"
    low: 0.0
    high: 0.1
    distribution: "uniform"

  gradient_accumulation_steps:
    type: "categorical"
    choices: [1, 2, 4, 8]

  per_device_train_batch_size:
    type: "categorical"
    choices: [1, 2, 4]

# Quantization parameters
quantization:
  bnb_4bit_quant_type:
    type: "categorical"
    choices: ["nf4", "fp4"]

  bnb_4bit_compute_dtype:
    type: "categorical"
    choices: ["bfloat16", "float16"]

  bnb_4bit_use_double_quant:
    type: "categorical"
    choices: [true, false]

# GPTQ-specific parameters (when using GPTQ)
gptq:
  group_size:
    type: "categorical"
    choices: [32, 64, 128]

  desc_act:
    type: "categorical"
    choices: [true, false]

  damp_percent:
    type: "float"
    low: 0.01
    high: 0.1
    distribution: "uniform"

# AWQ-specific parameters (when using AWQ)
awq:
  group_size:
    type: "categorical"
    choices: [32, 64, 128]

  zero_point:
    type: "categorical"
    choices: [true, false]

  version:
    type: "categorical"
    choices: ["GEMM", "GEMV"]

# Pruning/Sparsity parameters
sparsity:
  enable_2to4:
    type: "categorical"
    choices: [false, true]

  sparsity_ratio:
    type: "float"
    low: 0.0
    high: 0.7
    distribution: "uniform"
    condition: "enable_2to4 == false"

  recovery_finetune_epochs:
    type: "int"
    low: 0
    high: 2
    condition: "enable_2to4 == true"

# Runtime optimization parameters
runtime:
  flash_attn:
    type: "categorical"
    choices: [true, false]

  use_paged_attention:
    type: "categorical"
    choices: [false, true]

  max_sequence_length:
    type: "categorical"
    choices: [512, 1024, 2048]

  kv_cache_dtype:
    type: "categorical"
    choices: ["auto", "fp8", "fp16"]

# RAG parameters
rag:
  enable_rag:
    type: "categorical"
    choices: [false, true]

  top_k:
    type: "int"
    low: 3
    high: 8
    condition: "enable_rag == true"

  retrieval_threshold:
    type: "float"
    low: 0.5
    high: 0.9
    distribution: "uniform"
    condition: "enable_rag == true"

# Dataset augmentation parameters
data_augmentation:
  enable_calculator_annotation:
    type: "categorical"
    choices: [false, true]

  enable_numeric_jitter:
    type: "categorical"
    choices: [false, true]

  enable_unit_paraphrase:
    type: "categorical"
    choices: [false, true]

  enable_distractor_insertion:
    type: "categorical"
    choices: [false, true]

  augmentation_ratio:
    type: "float"
    low: 0.1
    high: 0.5
    distribution: "uniform"
    condition: "any(augmentation_enabled)"

# Evaluation parameters
evaluation:
  batch_size:
    type: "categorical"
    choices: [4, 8, 16, 32]

  num_samples_eval:
    type: "int"
    low: 100
    high: 1000
    step: 100

# Early stopping parameters
early_stopping:
  patience:
    type: "int"
    low: 3
    high: 12

  min_delta:
    type: "float"
    low: 0.001
    high: 0.01
    distribution: "log"

# Multi-objective optimization configuration
objectives:
  primary:
    - name: "accuracy"
      direction: "maximize"
      weight: 1.0

  secondary:
    - name: "latency_ms_p50"
      direction: "minimize"
      weight: 0.3

    - name: "vram_peak_mb"
      direction: "minimize"
      weight: 0.3

    - name: "co2_g"
      direction: "minimize"
      weight: 0.1

# Study configuration
study:
  n_trials: 100
  timeout_seconds: 3600  # 1 hour max per study
  n_startup_trials: 10   # Random trials before optimization
  n_jobs: 1             # Parallel trials (set based on GPU availability)

  # Optuna sampler configuration
  sampler:
    name: "TPESampler"
    args:
      n_startup_trials: 10
      n_ei_candidates: 24
      multivariate: true

  # Optuna pruner configuration
  pruner:
    name: "HyperbandPruner"
    args:
      min_resource: 1
      max_resource: 10
      reduction_factor: 3

# Resource constraints for HPO
resource_constraints:
  max_vram_per_trial_gb: 24
  max_time_per_trial_minutes: 30
  max_concurrent_trials: 2
  kill_on_memory_limit: true