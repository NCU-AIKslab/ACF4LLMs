{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b6fc77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ============================================================\n",
    "# Training (A100-40GB Colab) following your Mermaid workflow,\n",
    "# but reusing a *pretrained GRPO checkpoint* instead of retraining GRPO.\n",
    "#\n",
    "# Flow kept:\n",
    "#   A0 Datasets ‚Üí A1 Teacher Synthesis ‚Üí A2 Verification ‚Üí A3 SFT ‚Üí\n",
    "#   A4 (load your GRPO) ‚Üí A5 PRM ‚Üí A6 PRM-guided self-evolution ‚Üí\n",
    "#   A7 Length-aware finishing ‚Üí Eval\n",
    "# ============================================================\n",
    "\n",
    "# ============ A. ENV CHECK (no forced restarts) ============\n",
    "import importlib, sys, subprocess, platform, os, json, re, random, glob, shutil, time, traceback\n",
    "from pathlib import Path\n",
    "\n",
    "def ver(pkg):\n",
    "    try:\n",
    "        m = importlib.import_module(pkg); return getattr(m, \"__version__\", \"unknown\")\n",
    "    except Exception:\n",
    "        return \"not-installed\"\n",
    "\n",
    "print(\"Python  :\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"CUDA nvcc:\", subprocess.getoutput(\"nvcc --version | tail -n1\"))\n",
    "print(\"torch   :\", ver(\"torch\"))\n",
    "print(\"transformers:\", ver(\"transformers\"))\n",
    "print(\"trl        :\", ver(\"trl\"))\n",
    "print(\"accelerate  :\", ver(\"accelerate\"))\n",
    "print(\"peft        :\", ver(\"peft\"))\n",
    "print(\"datasets    :\", ver(\"datasets\"))\n",
    "\n",
    "# Tip: only install if you actually hit an import error below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea123b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ B. IMPORTS & GLOBAL CONFIG ============\n",
    "import torch, sympy as sp\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, GenerationConfig\n",
    ")\n",
    "from trl import SFTTrainer, SFTConfig, DPOTrainer, DPOConfig\n",
    "# GRPO is not used for training here; we only *load* your trained checkpoint for generation.\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ===== Paths (edit to your Drive if you want) =====\n",
    "BASE_DIR = Path(\"/content\")\n",
    "OUT  = BASE_DIR / \"outputs\"                  # notebook-local outputs\n",
    "DATA = BASE_DIR / \"data\"                     # notebook-local data\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you saved teacher/verified files on Drive, you can mount and point to them:\n",
    "# from google.colab import drive; drive.mount(\"/content/drive\")\n",
    "# DATA = Path(\"/content/drive/MyDrive/ncu_green_ai/data\"); DATA.mkdir(parents=True, exist_ok=True)\n",
    "# OUT  = Path(\"/content/drive/MyDrive/ncu_green_ai/output\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== Models =====\n",
    "# Base SFT starting point (you kept Qwen math 1.5B earlier)\n",
    "MODEL_ID  = os.getenv(\"MODEL_ID\", \"Qwen/Qwen2.5-Math-1.5B\")\n",
    "USE_INSTRUCT_CHAT_TEMPLATE = False  # True if using the Instruct chat template\n",
    "\n",
    "# *** IMPORTANT ***: your GRPO checkpoint path\n",
    "# Point this to the folder that contains config.json, pytorch_model.bin / safetensors, tokenizer files, etc.\n",
    "GRPO_MODEL_PATH = os.getenv(\"GRPO_MODEL_PATH\", \"/content/outputs/default-GRPO/final\")\n",
    "\n",
    "# ===== Training knobs (SFT, then later DPO/length-aware RL) =====\n",
    "MAX_SEQ_LEN = 4096\n",
    "SFT_EPOCHS  = 2\n",
    "SFT_LR      = 2e-5\n",
    "\n",
    "EVAL_N      = 200  # quick eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d17b5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ C. UTILITIES (parsers, verification) ============\n",
    "ANS_LINE = re.compile(r\"(?i)^Answer:\\s*(.+)\\s*$\")\n",
    "NUMERIC_TAIL = re.compile(r\"[-+]?\\d+(?:\\.\\d+)?(?:/[0-9]+)?\")\n",
    "\n",
    "def parse_final(text: str):\n",
    "    \"\"\"Robustly parse a final numeric answer from model output.\"\"\"\n",
    "    if not text: return None\n",
    "    # Prefer \\boxed{...}\n",
    "    m = re.findall(r\"\\\\boxed\\{([^}]+)\\}\", text)\n",
    "    if not m:\n",
    "        m = re.findall(r\"\\\\boxed\\{([^}\\n]+)\", text)  # tolerate missing brace\n",
    "    if m:\n",
    "        cand = m[-1].strip().strip(\"`'\\\"\")\n",
    "        t = NUMERIC_TAIL.search(cand)\n",
    "        return t.group(0) if t else None\n",
    "\n",
    "    # Next, look for last \"Answer: ...\":\n",
    "    matches = re.findall(r\"(?i)Answer:\\s*([^\\n]+)\", text)\n",
    "    if matches:\n",
    "        cand = matches[-1].strip().strip(\"`'\\\"\")\n",
    "        t = NUMERIC_TAIL.search(cand)\n",
    "        return t.group(0) if t else None\n",
    "\n",
    "    # Fallback: last non-empty line ‚Üí numeric tail\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    if not lines:\n",
    "        return None\n",
    "    t = NUMERIC_TAIL.search(lines[-1])\n",
    "    return t.group(0) if t else None\n",
    "\n",
    "def eq_correct(got, want):\n",
    "    try:\n",
    "        return sp.simplify(sp.nsimplify(got) - sp.nsimplify(want)) == 0\n",
    "    except Exception:\n",
    "        return str(got).strip() == str(want).strip()\n",
    "\n",
    "def extract_gold_gsm(answer_text: str):\n",
    "    m = re.search(r\"####\\s*([\\-+]?\\d+(?:\\.\\d+)?)\", answer_text)\n",
    "    return m.group(1).strip() if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b78c73",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ D. DATASETS (A0) ============\n",
    "print(\"Loading GSM8K‚Ä¶\")\n",
    "gsm = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "gsm_train = gsm[\"train\"]\n",
    "gsm_test  = gsm[\"test\"]\n",
    "print(\"GSM8K train/test:\", len(gsm_train), len(gsm_test))\n",
    "\n",
    "# (Optional) also parse some MATH set as before if you like.\n",
    "math_items = []  # keep empty unless you clone and parse hendrycks/MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec928fcc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ E. TEACHER SYNTHESIS (A1) + LOCAL VERIFICATION (A2) ============\n",
    "# If you already have verified PoT, we *reuse* it; otherwise we can synthesize.\n",
    "verified_path = DATA / \"teacher_verified.jsonl\"\n",
    "raw_path      = DATA / \"teacher_raw.jsonl\"\n",
    "\n",
    "def verify_record(rec):\n",
    "    \"\"\"Your safe Python verifier for PoT. Returns (ok, msg).\"\"\"\n",
    "    ALLOWED_BUILTINS = {\"abs\":abs, \"min\":min, \"max\":max, \"range\":range, \"len\":len, \"sum\":sum, \"print\":print}\n",
    "    SAFE_GLOBALS = {\n",
    "        \"__builtins__\": ALLOWED_BUILTINS,\n",
    "        \"math\": __import__(\"math\"), \"fractions\": __import__(\"fractions\"),\n",
    "        \"decimal\": __import__(\"decimal\"), \"itertools\": __import__(\"itertools\"), \"sp\": sp\n",
    "    }\n",
    "    code = rec[\"cot_program\"]; tests = rec.get(\"tests\", [])\n",
    "    final = str(rec.get(\"final_answer\",\"\")).strip()\n",
    "    if NUMERIC_TAIL.search(final) is None:\n",
    "        return False, \"final not numeric-like\"\n",
    "    loc = {}\n",
    "    try:\n",
    "        exec(code, SAFE_GLOBALS, loc)\n",
    "    except Exception as e:\n",
    "        return False, f\"exec error: {e}\"\n",
    "    for t in tests:\n",
    "        try:\n",
    "            exec(t, {**SAFE_GLOBALS, **loc}, {})\n",
    "        except Exception as e:\n",
    "            return False, f\"test fail: {e}\"\n",
    "    if \"solve\" in loc and callable(loc[\"solve\"]):\n",
    "        try:\n",
    "            got = str(loc[\"solve\"]()).strip()\n",
    "            try:\n",
    "                if sp.simplify(sp.nsimplify(got) - sp.nsimplify(final)) != 0:\n",
    "                    return False, f\"mismatch: solve()={got} vs final={final}\"\n",
    "            except Exception:\n",
    "                if got != final:\n",
    "                    return False, f\"mismatch: solve()={got} vs final={final}\"\n",
    "        except Exception as e:\n",
    "            return False, f\"solve() error: {e}\"\n",
    "    return True, \"ok\"\n",
    "\n",
    "# If verified exists, just load a tiny preview and count:\n",
    "if verified_path.exists() and verified_path.stat().st_size > 0:\n",
    "    n_verified = sum(1 for _ in open(verified_path))\n",
    "    print(f\"‚úÖ Using existing verified PoT: {verified_path} (records={n_verified})\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No verified PoT found; you can paste your earlier teacher-synthesis cell here if needed.\")\n",
    "    # You can synthesize with your OpenAI Teacher the same way you did before.\n",
    "    # Keeping the pipeline intact, but skipping here for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35b43b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ F. BUILD SFT DATASET (A3 input) ============\n",
    "def to_chat_text(q, prog, ans, tok, use_template=False):\n",
    "    system = \"You are a concise math solver. First write minimal Python to compute the answer, then output 'Answer: <value>'.\"\n",
    "    if use_template and hasattr(tok, \"apply_chat_template\"):\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":system},\n",
    "            {\"role\":\"user\",\"content\":q},\n",
    "            {\"role\":\"assistant\",\"content\":f\"# python\\n{prog}\\n\\nAnswer: {ans}\"}\n",
    "        ]\n",
    "        return tok.apply_chat_template(messages, tokenize=False)\n",
    "    else:\n",
    "        return f\"<|system|>\\n{system}\\n<|user|>\\n{q}\\n<|assistant|>\\n# python\\n{prog}\\n\\nAnswer: {ans}\"\n",
    "\n",
    "verified = []\n",
    "if verified_path.exists():\n",
    "    for line in open(verified_path):\n",
    "        try:\n",
    "            js = json.loads(line)\n",
    "            if all(k in js for k in [\"question\",\"cot_program\",\"final_answer\"]):\n",
    "                verified.append(js)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "sft_path = DATA / \"sft_train.jsonl\"\n",
    "if verified:\n",
    "    tok_tmp = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "    if tok_tmp.pad_token is None: tok_tmp.pad_token = tok_tmp.eos_token\n",
    "    with sft_path.open(\"w\") as f:\n",
    "        for r in verified:\n",
    "            text = to_chat_text(r[\"question\"], r[\"cot_program\"], r[\"final_answer\"], tok_tmp, USE_INSTRUCT_CHAT_TEMPLATE)\n",
    "            print(json.dumps({\"text\": text, \"question\": r[\"question\"], \"final_answer\": r[\"final_answer\"]}), file=f)\n",
    "    print(\"SFT records:\", sum(1 for _ in open(sft_path)))\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è No verified data ‚Üí SFT will be skipped unless you add teacher_verified.jsonl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b5d85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ G. SFT TRAINING (A3) ============\n",
    "if sft_path.exists():\n",
    "    train_ds = load_dataset(\"json\", data_files=str(sft_path))[\"train\"]\n",
    "    sft_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=\"auto\",\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    tok_sft = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "    if tok_sft.pad_token is None: tok_sft.pad_token = tok_sft.eos_token\n",
    "\n",
    "    sft_cfg = SFTConfig(\n",
    "        output_dir=str(OUT / \"sft-poT\"),\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=16,\n",
    "        learning_rate=SFT_LR,\n",
    "        num_train_epochs=SFT_EPOCHS,\n",
    "        bf16=True,\n",
    "        logging_steps=10,\n",
    "        save_steps=200,\n",
    "        gradient_checkpointing=True\n",
    "    )\n",
    "\n",
    "    def formatting_func(example):\n",
    "        q = example.get(\"question\", \"\")\n",
    "        ans = example.get(\"final_answer\", \"\")\n",
    "        return (\n",
    "            \"Solve the following math problem.\\n\\n\"\n",
    "            f\"{q}\\n\\n\"\n",
    "            \"Use minimal Python to compute, then end strictly with:\\n\"\n",
    "            f\"Answer: {ans}\\n\"\n",
    "        )\n",
    "\n",
    "    sft_trainer = SFTTrainer(\n",
    "        model=sft_model,\n",
    "        args=sft_cfg,\n",
    "        train_dataset=train_ds,\n",
    "        formatting_func=formatting_func,\n",
    "        tokenizer=tok_sft\n",
    "    )\n",
    "    sft_trainer.train()\n",
    "    sft_save = OUT / \"sft-poT\" / \"final\"\n",
    "    sft_trainer.save_model(str(sft_save))\n",
    "    tok_sft.save_pretrained(str(sft_save))\n",
    "    print(\"‚úÖ SFT saved ->\", sft_save)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping SFT (no sft_train.jsonl).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f17fc8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ H. LOAD YOUR TRAINED GRPO (A4 replacement) ============\n",
    "assert Path(GRPO_MODEL_PATH).exists(), (\n",
    "    f\"‚ùå GRPO_MODEL_PATH not found: {GRPO_MODEL_PATH}\\n\"\n",
    "    \"Set GRPO_MODEL_PATH to the directory of your trained GRPO checkpoint (contains config.json, tokenizer files, model weights).\"\n",
    ")\n",
    "\n",
    "print(f\"üîπ Using trained GRPO model from: {GRPO_MODEL_PATH}\")\n",
    "policy = AutoModelForCausalLM.from_pretrained(\n",
    "    GRPO_MODEL_PATH,\n",
    "    torch_dtype=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tok_policy = AutoTokenizer.from_pretrained(GRPO_MODEL_PATH, use_fast=True)\n",
    "if tok_policy.pad_token is None: tok_policy.pad_token = tok_policy.eos_token\n",
    "tok_policy.padding_side = \"left\"\n",
    "\n",
    "# Greedy-ish generation config for eval\n",
    "gen_cfg = GenerationConfig.from_model_config(policy.config)\n",
    "gen_cfg.do_sample = False\n",
    "gen_cfg.temperature = None\n",
    "gen_cfg.top_p = None\n",
    "gen_cfg.max_new_tokens = 192\n",
    "policy.generation_config = gen_cfg\n",
    "\n",
    "def make_prompt(question: str):\n",
    "    return (\n",
    "        \"Solve the problem briefly. Output ONLY one line:\\n\"\n",
    "        \"Answer: <number>\\n\\n\"\n",
    "        f\"Problem:\\n{question}\\n\\n\"\n",
    "        \"Answer: \"\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_once(model, tok, prompt, max_new_tokens=192):\n",
    "    inputs = tok([prompt], return_tensors=\"pt\").to(model.device)\n",
    "    newline_id = tok.encode(\"\\n\", add_special_tokens=False)[-1]\n",
    "    eos_ids = [tok.eos_token_id, newline_id] if newline_id is not None else tok.eos_token_id\n",
    "    out = model.generate(\n",
    "        **inputs, do_sample=False, max_new_tokens=max_new_tokens,\n",
    "        pad_token_id=tok.pad_token_id, eos_token_id=eos_ids\n",
    "    )[0]\n",
    "    text = tok.decode(out[inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return text.splitlines()[0].strip() if text else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbae47",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ I. PRM (A5) ============\n",
    "\n",
    "PRM_ID = \"Qwen/Qwen2.5-Math-PRM-7B\"\n",
    "prm_dir = OUT / \"prm\" / \"final\"\n",
    "\n",
    "try:\n",
    "    # Try pretrained PRM first\n",
    "    print(f\"üîπ Attempting to load pretrained PRM: {PRM_ID}\")\n",
    "    prm_tok = AutoTokenizer.from_pretrained(PRM_ID, use_fast=True)\n",
    "    prm_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        PRM_ID, torch_dtype=\"auto\", device_map=\"auto\"\n",
    "    ).eval()\n",
    "    print(\"‚úÖ Loaded pretrained PRM:\", PRM_ID)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Could not load pretrained PRM:\", e)\n",
    "    if prm_dir.exists():\n",
    "        # fallback to local fine-tuned PRM\n",
    "        print(\"‚úÖ Reusing existing PRM at:\", prm_dir)\n",
    "        prm_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            str(prm_dir), device_map=\"auto\", torch_dtype=\"auto\"\n",
    "        )\n",
    "        prm_tok   = AutoTokenizer.from_pretrained(str(prm_dir), use_fast=True)\n",
    "    else:\n",
    "        # fallback to PRM800K training\n",
    "        raw = _try_load_prm800k()\n",
    "        if raw is not None:\n",
    "            std = []\n",
    "            for ex in raw:\n",
    "                pair = _standardize_prm(ex)\n",
    "                if pair is not None:\n",
    "                    std.append(pair)\n",
    "            if std:\n",
    "                prm_train_ds = Dataset.from_list(std)\n",
    "                prm_tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "                if prm_tok.pad_token is None: prm_tok.pad_token = prm_tok.eos_token\n",
    "\n",
    "                def _tok_fn(ex):\n",
    "                    out = prm_tok(ex[\"text\"], truncation=True, max_length=1024)\n",
    "                    out[\"labels\"] = int(ex[\"label\"])\n",
    "                    return out\n",
    "\n",
    "                prm_ds_tok = prm_train_ds.map(_tok_fn, remove_columns=prm_train_ds.column_names)\n",
    "                prm_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    MODEL_ID, num_labels=2, torch_dtype=\"auto\", device_map=\"auto\"\n",
    "                )\n",
    "                prm_args = TrainingArguments(\n",
    "                    output_dir=str(OUT / \"prm\"),\n",
    "                    per_device_train_batch_size=4,\n",
    "                    gradient_accumulation_steps=2,\n",
    "                    learning_rate=1e-5, num_train_epochs=1,\n",
    "                    bf16=True, logging_steps=20, save_steps=200\n",
    "                )\n",
    "                prm_trainer = Trainer(model=prm_model, args=prm_args,\n",
    "                                      train_dataset=prm_ds_tok, tokenizer=prm_tok)\n",
    "                prm_trainer.train()\n",
    "                prm_trainer.save_model(str(prm_dir))\n",
    "                prm_tok.save_pretrained(str(prm_dir))\n",
    "                print(\"‚úÖ PRM trained & saved ->\", prm_dir)\n",
    "            else:\n",
    "                print(\"‚è≠Ô∏è PRM800K had no usable (text,label). Skipping PRM.\")\n",
    "                prm_model = None; prm_tok = None\n",
    "        else:\n",
    "            print(\"‚è≠Ô∏è PRM800K not found. Skipping PRM.\")\n",
    "            prm_model = None; prm_tok = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0987b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ J. PRM-GUIDED SELF-EVOLUTION (A6) ============\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Log which PRM source is being used\n",
    "if prm_model is None:\n",
    "    print(\"‚ö†Ô∏è PRM not available ‚Üí using uniform fallback score (0.5).\")\n",
    "elif \"Qwen2.5-Math-PRM-7B\" in getattr(prm_model.config, \"_name_or_path\", \"\"):\n",
    "    print(\"‚úÖ Using pretrained PRM: Qwen/Qwen2.5-Math-PRM-7B\")\n",
    "elif str(prm_dir) in getattr(prm_model.config, \"_name_or_path\", \"\"):\n",
    "    print(\"‚úÖ Using locally fine-tuned PRM (loaded from /prm/final)\")\n",
    "else:\n",
    "    print(\"‚úÖ Using custom-trained PRM (fallback from PRM800K or verified traces)\")\n",
    "\n",
    "def get_prm_score(question, code_line, step_num):\n",
    "    if prm_model is None:\n",
    "        return 0.5  # neutral fallback\n",
    "    txt = f\"{question}\\n\\n# step {step_num}\\n{code_line}\"\n",
    "    inputs = prm_tok(txt, return_tensors=\"pt\", truncation=True, max_length=1024).to(prm_model.device)\n",
    "    with torch.no_grad():\n",
    "        logits = prm_model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        return float(probs[0][1])  # P(correct)\n",
    "\n",
    "\n",
    "def best_of_n_with_prm(question, n=4, model=policy, tok=tok_policy):\n",
    "    candidates = []\n",
    "    for _ in range(n):\n",
    "        prompt = (\n",
    "            \"Write minimal Python to compute the result, then output only one line:\\n\"\n",
    "            \"Answer: <number>\\n\\n\"\n",
    "            f\"Problem:\\n{question}\\n\\n\"\n",
    "            \"Answer: \"\n",
    "        )\n",
    "        text = generate_once(model, tok, prompt, max_new_tokens=192)\n",
    "        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "        if not lines:\n",
    "            candidates.append((text, 0.0)); continue\n",
    "        scores = []\n",
    "        for i, line in enumerate(lines[:10]):\n",
    "            try: scores.append(get_prm_score(question, line, i+1))\n",
    "            except: scores.append(0.5)\n",
    "        avg_score = sum(scores)/len(scores) if scores else 0.0\n",
    "        candidates.append((text, avg_score))\n",
    "    return max(candidates, key=lambda x: x[1])\n",
    "\n",
    "print(\"üîÑ Generating PRM-guided enhanced data‚Ä¶\")\n",
    "enhanced_records = []\n",
    "evolution_samples = gsm_train.select(range(min(800, len(gsm_train))))\n",
    "for i, ex in enumerate(evolution_samples):\n",
    "    try:\n",
    "        text, s = best_of_n_with_prm(ex[\"question\"], n=4)\n",
    "        pred = parse_final(text)\n",
    "        gold = extract_gold_gsm(ex[\"answer\"])\n",
    "        if pred and gold and eq_correct(pred, gold) and s > 0.6:\n",
    "            enhanced_records.append({\n",
    "                \"question\": ex[\"question\"],\n",
    "                \"cot_program\": text,\n",
    "                \"final_answer\": pred,\n",
    "                \"prm_score\": s\n",
    "            })\n",
    "        if (i+1) % 50 == 0:\n",
    "            print(f\"[{i+1}/{len(evolution_samples)}] enhanced={len(enhanced_records)}\")\n",
    "    except Exception as e:\n",
    "        if i < 3: print(\"Example error:\", e)\n",
    "\n",
    "enhanced_path = DATA / \"prm_enhanced.jsonl\"\n",
    "with enhanced_path.open(\"w\") as f:\n",
    "    for rec in enhanced_records:\n",
    "        print(json.dumps(rec), file=f)\n",
    "print(\"‚úÖ Saved enhanced data:\", enhanced_path, \"count:\", len(enhanced_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa07cbc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ K. DPO (A7 part 1: long‚Üíshort preferences) ============\n",
    "# Build short-vs-long from verified (if present)\n",
    "pref_recs = []\n",
    "if verified:\n",
    "    def make_short(code: str, final_ans: str):\n",
    "        kept = []\n",
    "        for ln in code.splitlines():\n",
    "            s = ln.strip()\n",
    "            if s.startswith(\"#\"):      continue\n",
    "            if \"print(\" in s and \"Answer:\" not in s: continue\n",
    "            kept.append(ln)\n",
    "        return f\"{'\\n'.join(kept)}\\n\\nAnswer: {final_ans}\"\n",
    "\n",
    "    for r in verified[: min(1500, len(verified))]:\n",
    "        q = r[\"question\"]\n",
    "        long = f\"{r['cot_program']}\\n\\nAnswer: {r['final_answer']}\"\n",
    "        short = make_short(r[\"cot_program\"], r[\"final_answer\"])\n",
    "        pref_recs.append({\"prompt\": q, \"chosen\": short, \"rejected\": long})\n",
    "\n",
    "pref_path = DATA / \"short_vs_long.jsonl\"\n",
    "if pref_recs:\n",
    "    with pref_path.open(\"w\") as f:\n",
    "        for ex in pref_recs:\n",
    "            print(json.dumps(ex), file=f)\n",
    "    pref_ds = load_dataset(\"json\", data_files=str(pref_path))[\"train\"]\n",
    "\n",
    "    dpo_model = AutoModelForCausalLM.from_pretrained(\n",
    "        GRPO_MODEL_PATH,  # start DPO from your GRPO policy\n",
    "        torch_dtype=\"auto\", attn_implementation=\"flash_attention_2\", device_map=\"auto\"\n",
    "    )\n",
    "    dpo_cfg = DPOConfig(\n",
    "        output_dir=str(OUT / \"dpo\"),\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=8,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=5e-6,\n",
    "        bf16=True, logging_steps=20, save_steps=200,\n",
    "        max_length=1024\n",
    "    )\n",
    "    dpo_trainer = DPOTrainer(\n",
    "        model=dpo_model, ref_model=None, tokenizer=tok_policy,\n",
    "        args=dpo_cfg, train_dataset=pref_ds\n",
    "    )\n",
    "    dpo_trainer.train()\n",
    "    dpo_save = OUT / \"dpo\" / \"final\"\n",
    "    dpo_trainer.save_model(str(dpo_save))\n",
    "    tok_policy.save_pretrained(str(dpo_save))\n",
    "    print(\"‚úÖ DPO saved ->\", dpo_save)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è No verified data ‚Üí skipping DPO stage.\")\n",
    "    dpo_save = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67739646",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ L. Length-aware RL ‚Äúfinishing‚Äù (A7 part 2; optional) ============\n",
    "# For a simple ‚Äúlength-aware finishing‚Äù, we‚Äôll *not* run GRPO here to keep things light on Colab.\n",
    "# Instead we prepare a small shaping function and (optionally) do a tiny extra pass via DPO or SFT.\n",
    "# If you want true RL finishing, you can plug GRPO back in later starting from dpo_save or GRPO_MODEL_PATH.\n",
    "\n",
    "final_base_for_eval = str(dpo_save) if dpo_save is not None and Path(dpo_save).exists() else GRPO_MODEL_PATH\n",
    "print(\"üîπ Final base for eval:\", final_base_for_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8404144b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============ M. Evaluation (GSM8K quick pass@1) ============\n",
    "eval_model = AutoModelForCausalLM.from_pretrained(\n",
    "    final_base_for_eval, torch_dtype=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\", device_map=\"auto\"\n",
    ")\n",
    "eval_tok = AutoTokenizer.from_pretrained(final_base_for_eval, use_fast=True)\n",
    "if eval_tok.pad_token is None: eval_tok.pad_token = eval_tok.eos_token\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_gsm8k(n=EVAL_N):\n",
    "    subset = gsm_test.select(range(min(n, len(gsm_test))))\n",
    "    correct = 0\n",
    "    for i, ex in enumerate(subset):\n",
    "        prompt = make_prompt(ex[\"question\"])\n",
    "        text = generate_once(eval_model, eval_tok, prompt, max_new_tokens=192)\n",
    "        pred = parse_final(text)\n",
    "        gold = extract_gold_gsm(ex[\"answer\"])\n",
    "        good = (pred is not None and gold is not None and eq_correct(pred, gold))\n",
    "        correct += int(good)\n",
    "        if (i+1) % 20 == 0:\n",
    "            print(f\"[{i+1}/{len(subset)}] acc={correct/(i+1):.3f}\")\n",
    "    print(f\"Final GSM8K@{len(subset)}: acc={correct/len(subset):.3f}\")\n",
    "\n",
    "print(\"\\n‚ñ∂Ô∏è Running evaluation‚Ä¶\")\n",
    "evaluate_gsm8k(EVAL_N)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
