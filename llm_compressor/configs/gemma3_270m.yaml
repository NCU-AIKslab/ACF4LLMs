# Model configuration for Gemma 3 270M
  model:
    base_model: "openai-community/gpt2"     # GPT-2 開放模型，無需認證
    # base_model: "microsoft/DialoGPT-small"  # 也可以用這個
    # base_model: "google/gemma-2b"  # 需要認證
    sequence_length: 1024              # GPT-2 支援 1K context
    max_model_len: 1024

  # Hardware configuration (270M 模型需求較低)
  hardware:
    gpu: "NVIDIA RTX 4090"            # 或你實際的 GPU
    gpu_memory_utilization: 0.5       # 270M 模型不需要太多 VRAM
    vram_limit_gb: 8                  # 8GB 就足夠了
    tensor_parallel_size: 1

  # 調整約束條件 (小模型可能準確率較低)
  constraints:
    max_accuracy_drop: 0.05           # 允許 5% 準確率下降
    p95_latency_ms: 50                # 小模型延遲較低
    max_vram_gb: 8
    baseline_latency_ms: 30

  # 只啟用需要的 agents
  agents:
    data_curation:
      enabled: true
    recipe_planner:
      enabled: true                   # 啟用 recipe planning
    quantization:
      enabled: true                   # 啟用量化以測試功能
    kv_longcontext:
      enabled: true                   # 啟用 KV 優化
    pruning_sparsity:
      enabled: true                   # 啟用剪枝
    distillation:
      enabled: true                   # 啟用蒸餾
    rag:
      enabled: false
    perf_carbon:
      enabled: true
    eval_safety:
      enabled: true

  # 只評測 GSM8K
  evaluation:
    mmlu:
      enabled: false
    gsm8k:
      enabled: true
      num_samples: 500                # 可以調整樣本數量
    mtbench:
      enabled: false
    safety:
      enabled: false

  # vLLM 配置
  vllm:
    api_url: "http://localhost:8000"
    port: 8000
    max_model_len: 2048
    gpu_memory_utilization: 0.5