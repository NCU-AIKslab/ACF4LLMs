# Agentic Compression Framework

ä¸€å€‹æ™ºæ…§å‹æ¨¡å‹å£“ç¸®ç³»çµ±ï¼Œä½¿ç”¨ LangGraph å’Œ GPT-4o è‡ªå‹•å°‹æ‰¾æœ€ä½³å£“ç¸®ç­–ç•¥ï¼Œé€éå¤šç›®æ¨™å„ªåŒ–å¯¦ç¾è‡ªä¸»æ±ºç­–ã€‚

## æ¦‚è¿°

Agentic Compression Framework åªéœ€æœ€å°‘çš„è¼¸å…¥ï¼ˆæ¨¡å‹åç¨± + è³‡æ–™é›†ï¼‰ï¼Œå³å¯è‡ªå‹•å®Œæˆï¼š
- æ¨æ–·æ¨¡å‹è¦æ ¼èˆ‡éœ€æ±‚
- ç”± LLM è‡ªä¸»æå‡ºå£“ç¸®ç­–ç•¥
- åœ¨å¤šå€‹åŸºæº–æ¸¬è©¦ä¸Šè©•ä¼°å£“ç¸®å¾Œçš„æ¨¡å‹
- è¿½è¹¤æº–ç¢ºåº¦ã€å»¶é²ã€è¨˜æ†¶é«”å’Œæ¨¡å‹å¤§å°çš„ Pareto æœ€å„ªè§£
- æ ¹æ“šçµæœè¿­ä»£æ”¹é€²ç­–ç•¥

## ç‰¹è‰²åŠŸèƒ½

- **æœ€å°‘è¼¸å…¥**ï¼šåªéœ€æä¾›æ¨¡å‹åç¨±å’Œè³‡æ–™é›†ï¼Œç³»çµ±æœƒè‡ªå‹•æ¨æ–·å…¶ä»–è¨­å®š
- **LLM é©…å‹•æ±ºç­–**ï¼šä½¿ç”¨ GPT-4o ä½œç‚ºå”èª¿å™¨ï¼Œè‡ªä¸»æ±ºå®šå£“ç¸®ç­–ç•¥
- **å¤šæ–¹æ³•æ”¯æ´**ï¼šAutoRoundã€GPTQã€INT8ã€AWQã€å‰ªæã€è’¸é¤¾ã€LoRA/QLoRA
- **å®Œæ•´åŸºæº–æ¸¬è©¦**ï¼šGSM8Kã€CommonsenseQAã€TruthfulQAã€HumanEvalã€BIG-Bench Hard
- **å¤šç›®æ¨™å„ªåŒ–**ï¼šè·¨å¤šå€‹æŒ‡æ¨™è¿½è¹¤ Pareto å‰ç·£
- **LangGraph æ¶æ§‹**ï¼šåŸºæ–¼ç‹€æ…‹æ©Ÿçš„å·¥ä½œæµç¨‹ï¼Œå¯é ä¸”å¯è¿½è¹¤

## å¿«é€Ÿé–‹å§‹

### å®‰è£

```bash
# è¤‡è£½å°ˆæ¡ˆ
git clone <repository_url>
cd Green_AI

# å»ºç«‹ conda ç’°å¢ƒ
conda create -n greenai python=3.10
conda activate greenai
pip install -r requirements.txt

# ï¼ˆé¸ç”¨ï¼‰å®‰è£ GPU é‡åŒ–å™¨ï¼ˆéœ€è¦ CUDA å·¥å…·éˆï¼‰
export CUDA_HOME=/usr/lib/nvidia-cuda-toolkit  # æ›´æ–°ç‚ºä½ çš„ CUDA è·¯å¾‘
pip install -r requirements.quantization.txt
```

### è¨­å®šç’°å¢ƒè®Šæ•¸

```bash
# å¿…é ˆè¨­å®š OpenAI API Key
export OPENAI_API_KEY=sk-your-api-key-here

# ï¼ˆé¸ç”¨ï¼‰è¨­å®š HuggingFace Tokenï¼ˆç”¨æ–¼å—é™æ¨¡å‹ï¼‰
export HF_TOKEN=hf_your-token-here
```

## ä½¿ç”¨ç¯„ä¾‹

### åŸºæœ¬å£“ç¸®å„ªåŒ–

```bash
# æœ€ç°¡å–®çš„ç”¨æ³• - å£“ç¸® GPT-2 ä¸¦é‡å° GSM8K å„ªåŒ–
python scripts/run_pipeline.py --model gpt2 --dataset gsm8k

# æŒ‡å®šæ›´å¤šå›åˆä»¥ç²å¾—æ›´å¥½çš„å„ªåŒ–çµæœ
python scripts/run_pipeline.py \
    --model meta-llama/Meta-Llama-3-8B-Instruct \
    --dataset commonsenseqa \
    --episodes 10

# äº’å‹•æ¨¡å¼ - å³æ™‚é¡¯ç¤ºé€²åº¦
python scripts/run_pipeline.py \
    --model mistralai/Mistral-7B-v0.1 \
    --dataset humaneval \
    --interactive

# è‡ªè¨‚å¯¦é©—åç¨±å’Œæ™‚é–“é ç®—
python scripts/run_pipeline.py \
    --model Qwen/Qwen2-7B \
    --dataset truthfulqa \
    --episodes 5 \
    --budget 4.0 \
    --experiment-name "qwen2_truthful_opt"
```

### æŸ¥çœ‹æ¨¡å‹è¦æ ¼

åœ¨åŸ·è¡Œå£“ç¸®å‰ï¼Œå…ˆæŸ¥çœ‹ç³»çµ±è‡ªå‹•æ¨æ–·çš„æ¨¡å‹è¦æ ¼ï¼š

```bash
python scripts/run_pipeline.py \
    --model meta-llama/Meta-Llama-3-8B-Instruct \
    --dataset gsm8k \
    --show-spec
```

è¼¸å‡ºç¯„ä¾‹ï¼š
```
ğŸ“Š Model Specification
========================
Model: meta-llama/Meta-Llama-3-8B-Instruct
Parameters: 8.03B
Architecture: LlamaForCausalLM
Original Size: 16.06 GB (FP16)

Recommended Methods: autoround, gptq, awq
Target Benchmark: gsm8k
Estimated VRAM: 20.0 GB (for quantization)
```

### åˆ†æå¯¦é©—çµæœ

```bash
# æ‘˜è¦æª¢è¦–
python scripts/run_pipeline.py analyze data/experiments/your_experiment_dir

# è©³ç´°æª¢è¦– - é¡¯ç¤ºæ‰€æœ‰ Pareto è§£
python scripts/run_pipeline.py analyze data/experiments/your_experiment_dir --format detailed

# JSON æ ¼å¼è¼¸å‡º - æ–¹ä¾¿ç¨‹å¼è™•ç†
python scripts/run_pipeline.py analyze data/experiments/your_experiment_dir --format json
```

### å®Œæ•´ç¯„ä¾‹ï¼šå£“ç¸® Llama-3-8B

```bash
# 1. è¨­å®šç’°å¢ƒè®Šæ•¸
export OPENAI_API_KEY=sk-your-api-key
export HF_TOKEN=hf_your-token  # Llama-3 éœ€è¦æˆæ¬Š

# 2. æŸ¥çœ‹æ¨¡å‹è¦æ ¼
python scripts/run_pipeline.py \
    --model meta-llama/Meta-Llama-3-8B-Instruct \
    --dataset gsm8k \
    --show-spec

# 3. åŸ·è¡Œå£“ç¸®å„ªåŒ–ï¼ˆ10 å›åˆï¼Œ4 å°æ™‚é ç®—ï¼‰
python scripts/run_pipeline.py \
    --model meta-llama/Meta-Llama-3-8B-Instruct \
    --dataset gsm8k \
    --episodes 10 \
    --budget 4.0 \
    --interactive \
    --experiment-name "llama3_gsm8k_optimization"

# 4. åˆ†æçµæœ
python scripts/run_pipeline.py analyze \
    data/experiments/llama3_gsm8k_optimization \
    --format detailed
```

### æ‰‹å‹•è©•ä¼°å·²å£“ç¸®çš„æ¨¡å‹

```bash
python run_manual_eval.py \
    --model-path ./compressed_models/llama3-8b-4bit \
    --benchmark gsm8k \
    --output-dir ./eval_results
```

## æ¶æ§‹

### LangGraph ç‹€æ…‹æ©Ÿ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangGraph Workflow                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚   START â”€â”€â–º coordinator â”€â”€â”¬â”€â”€â–º quantization â”€â”€â–º eval   â”‚
â”‚                 â–²         â”‚         â”‚                   â”‚
â”‚                 â”‚         â”‚         â–¼                   â”‚
â”‚                 â”‚         â”‚    update_state            â”‚
â”‚                 â”‚         â”‚         â”‚                   â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                 â”‚                                       â”‚
â”‚                 â””â”€â”€â–º search â”€â”€â”˜                         â”‚
â”‚                 â”‚                                       â”‚
â”‚                 â””â”€â”€â–º END                                â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒå…ƒä»¶

| å…ƒä»¶ | æª”æ¡ˆ | èªªæ˜ |
|------|------|------|
| LangGraph å”èª¿å™¨ | `src/coordinator/langgraph_coordinator.py` | ä½¿ç”¨ GPT-4o çš„ LLM é©…å‹•å”èª¿å™¨ |
| ç‹€æ…‹ç®¡ç† | `src/coordinator/state.py` | LangGraph ç‹€æ…‹ schema |
| è¦æ ¼æ¨æ–· | `src/coordinator/spec_inference.py` | è‡ªå‹•æ¨æ–·æ¨¡å‹è¦æ ¼ |
| Pareto å‰ç·£ | `src/coordinator/pareto.py` | å¤šç›®æ¨™å„ªåŒ–è¿½è¹¤ |
| é‡åŒ–ä»£ç† | `src/agents/quantization_agent.py` | é‡åŒ–å·¥å…·ï¼ˆAutoRoundã€GPTQã€AWQã€INT8ï¼‰ |
| è©•ä¼°ä»£ç† | `src/agents/evaluation_agent.py` | åŸºæº–æ¸¬è©¦è©•ä¼° |

### LLM å”èª¿å™¨å·¥ä½œæµç¨‹

1. **åˆ†æç‹€æ…‹**ï¼šGPT-4o åˆ†æç•¶å‰ Pareto å‰ç·£å’Œæ­·å²è¨˜éŒ„
2. **æ±ºå®šç­–ç•¥**ï¼šè‡ªä¸»æ±ºå®šä¸‹ä¸€å€‹å£“ç¸®ç­–ç•¥ï¼ˆæ–¹æ³•ã€ä½å…ƒæ•¸ç­‰ï¼‰
3. **åŸ·è¡Œå£“ç¸®**ï¼šèª¿ç”¨é‡åŒ–å·¥å…·åŸ·è¡Œå£“ç¸®
4. **è©•ä¼°çµæœ**ï¼šåœ¨ç›®æ¨™åŸºæº–æ¸¬è©¦ä¸Šè©•ä¼°å£“ç¸®å¾Œçš„æ¨¡å‹
5. **æ›´æ–°å‰ç·£**ï¼šå¦‚æœçµæœæ˜¯éæ”¯é…è§£ï¼ŒåŠ å…¥ Pareto å‰ç·£
6. **è¿­ä»£**ï¼šæ ¹æ“šçµæœæ±ºå®šæ˜¯å¦ç¹¼çºŒæˆ–çµ‚æ­¢

## æ”¯æ´çš„æ¨¡å‹

æ¡†æ¶æ”¯æ´ä»»ä½• HuggingFace æ¨¡å‹ï¼Œé‡å°ä»¥ä¸‹æ¨¡å‹æœ‰å„ªåŒ–è¨­å®šï¼š

| æ¨¡å‹ç³»åˆ— | ç¯„ä¾‹ | æ¨è–¦é‡åŒ–æ–¹æ³• |
|----------|------|--------------|
| Llama | Llama-2-7B, Llama-3-8B | AutoRound, GPTQ, AWQ |
| Mistral | Mistral-7B, Mixtral-8x7B | AutoRound, GPTQ |
| Qwen | Qwen2-7B, Qwen2.5-14B | GPTQ, AWQ |
| GPT-2 | gpt2, gpt2-medium | INT8, GPTQ |

## åŸºæº–æ¸¬è©¦

| åŸºæº–æ¸¬è©¦ | èªªæ˜ | è©•ä¼°æŒ‡æ¨™ |
|----------|------|----------|
| GSM8K | æ•¸å­¸æ¨ç† | æº–ç¢ºç‡ |
| CommonsenseQA | å¸¸è­˜æ¨ç† | æº–ç¢ºç‡ |
| TruthfulQA | çœŸå¯¦æ€§èˆ‡äº‹å¯¦æ€§ | MC1/MC2 åˆ†æ•¸ |
| HumanEval | ç¨‹å¼ç¢¼ç”Ÿæˆ | pass@1 |
| BIG-Bench Hard | å¤šå…ƒå›°é›£ä»»å‹™ | æº–ç¢ºç‡ |

## å¯¦é©—ç›®éŒ„çµæ§‹

```
data/experiments/{experiment_name}/
â”œâ”€â”€ model_spec.json          # æ¨æ–·çš„æ¨¡å‹è¦æ ¼
â”œâ”€â”€ pareto_frontier.json     # Pareto æœ€å„ªè§£
â”œâ”€â”€ final_results.json       # å„ªåŒ–æ‘˜è¦
â”œâ”€â”€ pareto_visualization.html # äº’å‹•å¼è¦–è¦ºåŒ–
â””â”€â”€ episode_xxx/
    â”œâ”€â”€ strategy.json        # å£“ç¸®ç­–ç•¥
    â””â”€â”€ results.json         # è©•ä¼°çµæœ
```

## CLI é¸é …åƒè€ƒ

```
python scripts/run_pipeline.py [OPTIONS]

é¸é …:
  -m, --model TEXT          HuggingFace æ¨¡å‹åç¨±æˆ–è·¯å¾‘ [å¿…å¡«]
  -d, --dataset TEXT        ç›®æ¨™è³‡æ–™é›† [å¿…å¡«]
                            å¯é¸: gsm8k, commonsenseqa, truthfulqa,
                                  humaneval, bigbench_hard
  -e, --episodes INTEGER    æœ€å¤§å£“ç¸®å›åˆæ•¸ [é è¨­: 3]
  -b, --budget FLOAT        æ™‚é–“é ç®—ï¼ˆå°æ™‚ï¼‰[é è¨­: 2.0]
  -n, --experiment-name TEXT å¯¦é©—åç¨± [è‡ªå‹•ç”¢ç”Ÿ]
  -i, --interactive         äº’å‹•æ¨¡å¼ï¼Œé¡¯ç¤ºé€²åº¦æ›´æ–°
  --show-spec               é¡¯ç¤ºæ¨æ–·çš„è¦æ ¼å¾Œé€€å‡º
  -o, --output-dir TEXT     è¼¸å‡ºç›®éŒ„ [é è¨­: data/experiments]
  -c, --config PATH         è¨­å®šæª”è·¯å¾‘ï¼ˆJSON æˆ– YAMLï¼‰
  --help                    é¡¯ç¤ºèªªæ˜
```

## é–‹ç™¼ç‹€æ…‹

### éšæ®µ 1ï¼ˆMVPï¼‰âœ… å®Œæˆ
- åŸºæœ¬å”èª¿å™¨èˆ‡è¦æ ¼æ¨æ–·
- Pareto å‰ç·£è¿½è¹¤
- CLI ä»‹é¢

### éšæ®µ 2 âœ… å®Œæˆ
- LangGraph é‡æ§‹
- GPT-4o LLM é©…å‹•æ±ºç­–
- çœŸå¯¦é‡åŒ–å·¥å…·æ•´åˆ

### éšæ®µ 3ï¼ˆé€²è¡Œä¸­ï¼‰
- å®Œæ•´åŸºæº–æ¸¬è©¦å¯¦ä½œ
- å‰ªæä»£ç†
- å¾®èª¿ä»£ç†ï¼ˆLoRA/QLoRAï¼‰

### éšæ®µ 4ï¼ˆè¨ˆåŠƒä¸­ï¼‰
- è’¸é¤¾æ”¯æ´
- MLflow æ•´åˆ
- Streamlit å„€è¡¨æ¿
- Docker éƒ¨ç½²

## æ¸¬è©¦

```bash
# åŸ·è¡ŒåŸºæœ¬æ¸¬è©¦
pytest tests/

# åŸ·è¡Œç«¯å°ç«¯æ¸¬è©¦
python scripts/run_pipeline.py \
    --model gpt2 \
    --dataset gsm8k \
    --episodes 2
```

## æˆæ¬Š

MIT License

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨æ­¤æ¡†æ¶ï¼Œè«‹å¼•ç”¨ï¼š

```bibtex
@software{agentic_compression,
  title = {Agentic Compression Framework},
  year = {2024},
  author = {Your Name},
  url = {repository_url}
}
```

## è‡´è¬

- ä½¿ç”¨ [LangGraph](https://github.com/langchain-ai/langgraph) å»ºæ§‹å·¥ä½œæµç¨‹
- å£“ç¸®å‡½å¼åº«ï¼šAutoRoundã€GPTQã€PEFTã€AWQ
- è©•ä¼°ç”± [lm-eval](https://github.com/EleutherAI/lm-evaluation-harness) é©…å‹•
- LLM å”èª¿ç”± OpenAI GPT-4o æä¾›

## è¯çµ¡æ–¹å¼

å¦‚æœ‰å•é¡Œæˆ–éœ€è¦æ”¯æ´ï¼Œè«‹åœ¨ GitHub ä¸Šé–‹å•Ÿ issueã€‚
